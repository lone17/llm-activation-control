{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3552a64",
   "metadata": {},
   "source": [
    "In this notebook, we get the constrastive sets of activations by creating checkpoints at start think and end think tokens:\n",
    "\n",
    "```md\n",
    "thinking:\n",
    "\tWhat is LLM?<think>\\n\\nOkay the user ask...</think>\\n\\nLLM is...\n",
    "\t\t\t^                               ^\n",
    "\t\t        Here                            Here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a178a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers transformers_stream_generator tiktoken transformer_lens einops jaxtyping colorama kaleido numpy==1.26.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8106d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "import einops\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import TypedDict, Literal\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from typing import Callable\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from jaxtyping import Float, Int\n",
    "from enum import StrEnum\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a62a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"Qwen/Qwen3-4B\"\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained_no_processing(\n",
    "    MODEL_PATH,\n",
    "    device=DEVICE,\n",
    "    dtype=torch.float16,\n",
    "    default_padding_side='left',\n",
    "    # fp16=True\n",
    ")\n",
    "\n",
    "model.tokenizer.padding_side = 'left'\n",
    "# model.tokenizer.pad_token = '<|extra_0|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beced8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The second model is optional, but we can use to to leverage the second GPU on Kaggle Notebook\n",
    "DEVICE_2 = \"cuda:1\"\n",
    "\n",
    "model_2 = HookedTransformer.from_pretrained_no_processing(\n",
    "    MODEL_PATH,\n",
    "    device=DEVICE_2,\n",
    "    dtype=torch.float16,\n",
    "    default_padding_side='left',\n",
    "    # fp16=True\n",
    ")\n",
    "\n",
    "model_2.tokenizer.padding_side = 'left'\n",
    "# model.tokenizer.pad_token = '<|extra_0|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a45821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_instructions_qwen_chat(\n",
    "    tokenizer: AutoTokenizer,\n",
    "    instructions: list[str],\n",
    "    enable_thinking: bool = True,\n",
    ") -> Int[Tensor, \"batch_size seq_len\"]:\n",
    "    prompts = []\n",
    "    for instruction in instructions:\n",
    "        message = [{\"role\": \"user\", \"content\": instruction}]\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            message,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,\n",
    "            enable_thinking=enable_thinking,\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return tokenizer(prompts, padding=True, truncation=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "tokenize_instructions_enable_thinking_fn = functools.partial(\n",
    "    tokenize_instructions_qwen_chat,\n",
    "    tokenizer=model.tokenizer,\n",
    "    enable_thinking=True,\n",
    ")\n",
    "\n",
    "tokenize_instructions_disable_thinking_fn = functools.partial(\n",
    "    tokenize_instructions_qwen_chat,\n",
    "    tokenizer=model.tokenizer,\n",
    "    enable_thinking=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70bdd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_instructions() -> tuple[list[str], list[str]]:\n",
    "    url = \"https://raw.githubusercontent.com/cvenhoff/steering-thinking-llms/refs/heads/main/messages/messages.py\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    # Save to file\n",
    "    with open(\"messages.py\", \"w\") as f:\n",
    "        f.write(response.text)\n",
    "    \n",
    "    # Load the messages\n",
    "    assert Path(\"messages.py\").exists()\n",
    "    from messages import messages, eval_messages\n",
    "\n",
    "    train_contents = [msg[\"content\"] for msg in messages]\n",
    "    eval_contents = [msg[\"content\"] for msg in eval_messages]\n",
    "\n",
    "    # Shuffle the messages\n",
    "    # random.shuffle(train_contents)\n",
    "    # random.shuffle(eval_contents)\n",
    "\n",
    "    return train_contents, eval_contents\n",
    "\n",
    "instructions_train, instructions_test = get_dataset_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a616e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_instructions(instructions: list[str]) -> list[str]:\n",
    "    return [ins + \" Think fast and briefly.\" for ins in instructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb14b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_train = preprocess_instructions(instructions_train)\n",
    "instructions_test = preprocess_instructions(instructions_test)\n",
    "\n",
    "print(f\"instructions_train: {len(instructions_train)}\")\n",
    "print(f\"instructions_test: {len(instructions_test)}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"instructions_train:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(instructions_train[i])}\")\n",
    "print(\"instructions_test:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(instructions_test[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500ed6f",
   "metadata": {},
   "source": [
    "## Compute directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_BATCH_SIZE =16\n",
    "MAX_NEW_TOKENS = -1\n",
    "UPPERBOUND_MAX_NEW_TOKENS = 5000\n",
    "\n",
    "start_thinking_token_id = 151667\n",
    "end_thinking_token_id = 151668 # Qwen3's end of thinking token id\n",
    "n_layers = model.cfg.n_layers\n",
    "n_activations = 2\n",
    "d_model = model.cfg.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = instructions_train[:TRAIN_BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a67b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "def generate_with_token_specific_activations(\n",
    "    model: HookedTransformer,\n",
    "    tokens: torch.Tensor,\n",
    "    target_tokens: list[str] = [\"<think>\", \"</think>\"],\n",
    "    max_new_tokens: int | None = None,\n",
    "    activation_types: list[str] = [\"resid_mid\", \"resid_post\"],\n",
    "    layers: list[int] | None = None,\n",
    "    offload_to_cpu: bool = True,\n",
    ") -> tuple[dict[str, dict[tuple[str, int], torch.Tensor]], torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generate text and only extract activations when specific tokens are generated.\n",
    "    \n",
    "    Returns:\n",
    "        activations: {token_str: {(act_type, layer): tensor}}\n",
    "        final_tokens: generated sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    if layers is None:\n",
    "        layers = list(range(model.cfg.n_layers))\n",
    "\n",
    "    if max_new_tokens is None:\n",
    "        max_new_tokens = UPPERBOUND_MAX_NEW_TOKENS\n",
    "    \n",
    "    # Convert target tokens to token IDs\n",
    "    target_token_ids = set()\n",
    "    target_token_to_str = {}  # Map token_id back to string for storage\n",
    "    \n",
    "    for token_str in target_tokens:\n",
    "        # Handle both single tokens and multi-token strings\n",
    "        token_ids = model.tokenizer(token_str, return_tensors=\"pt\").input_ids.squeeze()\n",
    "        if token_ids.dim() == 0:\n",
    "            token_ids = [token_ids.item()]\n",
    "        else:\n",
    "            token_ids = token_ids.tolist()\n",
    "        \n",
    "        # For simplicity, assume target tokens are single tokens\n",
    "        # You might need to handle multi-token strings differently\n",
    "        if len(token_ids) == 1:\n",
    "            target_token_ids.add(token_ids[0])\n",
    "            target_token_to_str[token_ids[0]] = token_str\n",
    "        else:\n",
    "            print(f\"Warning: {token_str} tokenizes to multiple tokens: {token_ids}\")\n",
    "            # Handle multi-token case - take the last token as trigger\n",
    "            target_token_ids.add(token_ids[-1])\n",
    "            target_token_to_str[token_ids[-1]] = token_str\n",
    "    \n",
    "    print(f\"Monitoring token IDs: {target_token_ids}\")\n",
    "    print(f\"Token mapping: {target_token_to_str}\")\n",
    "\n",
    "    is_monitored: dict[int, bool] = {token_id: False for token_id in target_token_ids}\n",
    "    \n",
    "    # Storage for activations at specific tokens\n",
    "    token_activations = {token_str: {} for token_str in target_tokens}\n",
    "    \n",
    "    batch_size = tokens.shape[0]\n",
    "    d_model = model.cfg.d_model\n",
    "    device = tokens.device\n",
    "    \n",
    "    # Initialize storage for each target token\n",
    "    for token_str in target_tokens:\n",
    "        token_activations[token_str] = {}\n",
    "    \n",
    "    for step in tqdm(range(max_new_tokens), desc=\"Generating\"):\n",
    "        model.reset_hooks()\n",
    "        with torch.no_grad():\n",
    "            # Regular forward pass (no caching) - much faster\n",
    "            logits = model(tokens)\n",
    "            next_token = logits[:, -1, :].argmax(dim=-1)\n",
    "            \n",
    "            # Check if the generated token is one we're monitoring\n",
    "            if next_token.item() in target_token_ids and not is_monitored[next_token.item()]:\n",
    "                is_monitored[next_token.item()] = True\n",
    "                token_str = target_token_to_str[next_token.item()]\n",
    "                print(f\"Step {step}: Found target token '{token_str}' (ID: {next_token.item()})\")\n",
    "                \n",
    "                # NOW we extract activations with the full sequence including this token\n",
    "                tokens_with_new = torch.cat([tokens, next_token.unsqueeze(1)], dim=1)\n",
    "                \n",
    "                # Extract activations using hooks\n",
    "                step_activations = {}\n",
    "                \n",
    "                def make_hook(act_type: str, layer: int):\n",
    "                    def hook_fn(activation, hook):\n",
    "                        # Get activation at the position of our target token (last position)\n",
    "                        nonlocal step_activations\n",
    "\n",
    "                        target_activation = activation[:, -1, :].clone()\n",
    "                        if offload_to_cpu:\n",
    "                            target_activation = target_activation.cpu()\n",
    "                        step_activations[(act_type, layer)] = target_activation\n",
    "                    return hook_fn\n",
    "                \n",
    "                hooks = []\n",
    "                for layer in layers:\n",
    "                    for act_type in activation_types:\n",
    "                        hook_name = f\"blocks.{layer}.hook_{act_type}\"\n",
    "                        if hook_name not in model.hook_dict:\n",
    "                            raise ValueError(f\"{hook_name} not found in hook dict\")\n",
    "                        hook = model.add_hook(hook_name, make_hook(act_type, layer))\n",
    "                        hooks.append(hook)\n",
    "                \n",
    "                # Forward pass with hooks to get activations\n",
    "                with torch.no_grad():\n",
    "                    _ = model(tokens_with_new)\n",
    "                \n",
    "                # Remove hooks\n",
    "                # print(f\"Current hooks: {hooks}\")\n",
    "                # for hook in hooks:\n",
    "                #     hook.remove()\n",
    "                \n",
    "                # Store the activations\n",
    "                for (act_type, layer), activation in step_activations.items():\n",
    "                    token_activations[token_str][(act_type, layer)] = activation\n",
    "                \n",
    "                # Update tokens\n",
    "                tokens = tokens_with_new\n",
    "                \n",
    "                # Clean up\n",
    "                del step_activations\n",
    "            else:\n",
    "                # Regular token - just append without activation extraction\n",
    "                tokens = torch.cat([tokens, next_token.unsqueeze(1)], dim=1)\n",
    "            \n",
    "            # Clean up\n",
    "            del logits\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        if all(is_monitored.values()):\n",
    "            break\n",
    "    \n",
    "    return token_activations, tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98823a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_positive_caches = []\n",
    "batch_negative_caches = []\n",
    "\n",
    "for i, instruction in enumerate(instructions):\n",
    "    print(f\"Processing instruction {i}:\")\n",
    "    tokens = tokenize_instructions_enable_thinking_fn(instructions=[instruction])\n",
    "    print(f\"Number of tokens: {tokens.shape[1]}\")\n",
    "    token_activations, tokens = generate_with_token_specific_activations(\n",
    "        model,\n",
    "        tokens.to(DEVICE),\n",
    "        max_new_tokens=None,\n",
    "        activation_types=[\"resid_mid\", \"resid_post\"],\n",
    "        target_tokens=[\"<think>\", \"</think>\"],\n",
    "    )\n",
    "    batch_positive_caches.append(token_activations[\"<think>\"])\n",
    "    batch_negative_caches.append(token_activations[\"</think>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(batch_positive_caches) == len(batch_negative_caches) == TRAIN_BATCH_SIZE\n",
    "\n",
    "print(batch_positive_caches[0][\"resid_mid\", 0].shape) # (1, d_model)\n",
    "print(batch_negative_caches[0][\"resid_post\", 0].shape) # (1, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save activations for backup\n",
    "\n",
    "def save_tensor(\n",
    "    tensor: Tensor,\n",
    "    save_dir: Path,\n",
    "    name: str,\n",
    ") -> None:\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    save_path = save_dir / f\"{name}.pt\"\n",
    "    torch.save(tensor, save_path)\n",
    "    print(f\"Saved {name} to {save_path}\")\n",
    "\n",
    "backup_dir = Path(\"outputs/\")\n",
    "backup_dir.mkdir(exist_ok=True, parents=True)\n",
    "save_tensor(batch_positive_caches, backup_dir, \"batch_positive_caches_HookedTransformer\")\n",
    "save_tensor(batch_negative_caches, backup_dir, \"batch_negative_caches_HookedTransformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1ed79",
   "metadata": {},
   "source": [
    "### Compute positive activations (at `<think>`) and negative activations (at `</think>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean activations across batch dimension\n",
    "positive_mean_activations = torch.zeros(\n",
    "    n_layers, n_activations, d_model, device=DEVICE, dtype=torch.float16\n",
    ") # (n_layers, n_activations, d_model)\n",
    "\n",
    "# All activations within the batch\n",
    "positive_activations_all = torch.zeros(\n",
    "    n_layers, n_activations, TRAIN_BATCH_SIZE, d_model, device=DEVICE, dtype=torch.float16\n",
    ") # (n_layers, n_activations, batch_size, d_model)\n",
    "\n",
    "\n",
    "for layer in range(n_layers):\n",
    "    batch_positive_activations = []\n",
    "    for act in [\"resid_mid\", \"resid_post\"]:\n",
    "        # Get mean activations across tokens dimension\n",
    "        batch_positive_activations_per_act = torch.stack([\n",
    "            sample[act, layer][0, :] for sample in batch_positive_caches\n",
    "        ]) # (batch_size, d_model)\n",
    "        batch_positive_activations.append(batch_positive_activations_per_act)\n",
    "    batch_positive_activations = torch.stack(batch_positive_activations) # (n_activations, batch_size, d_model)\n",
    "\n",
    "    # Normalize then get mean because the activation will be normalized by the RMSNorm layer\n",
    "    batch_positive_activations = batch_positive_activations / batch_positive_activations.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Compute mean across batch dimension\n",
    "    positive_mean_activations[layer] = batch_positive_activations.mean(dim=1)\n",
    "    positive_activations_all[layer] = batch_positive_activations\n",
    "\n",
    "print(positive_mean_activations.shape) # (n_layers, n_activations, num_last_tokens, d_model)\n",
    "print(positive_activations_all.shape) # (n_layers, n_activations, batch_size, num_last_tokens, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de790ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mean_activations = torch.zeros(\n",
    "    n_layers, n_activations, d_model, device=DEVICE, dtype=torch.float16\n",
    ") # (n_layers, n_activations, d_model)\n",
    "\n",
    "negative_activations_all = torch.zeros(\n",
    "    n_layers, n_activations, TRAIN_BATCH_SIZE, d_model, device=DEVICE, dtype=torch.float16\n",
    ") # (n_layers, n_activations, batch_size, d_model)\n",
    "\n",
    "for layer in range(n_layers):\n",
    "    batch_negative_activations = []\n",
    "    for act in [\"resid_mid\", \"resid_post\"]:\n",
    "        # Get mean activations across tokens dimension\n",
    "        batch_negative_activations_per_act = torch.stack([\n",
    "            sample[act, layer][0, :] for sample in batch_negative_caches\n",
    "        ]) # (batch_size, d_model)\n",
    "        batch_negative_activations.append(batch_negative_activations_per_act)\n",
    "    batch_negative_activations = torch.stack(batch_negative_activations) # (n_activations, batch_size, d_model)\n",
    "\n",
    "    # Normalize then get mean because the activation will be normalized by the RMSNorm layer\n",
    "    batch_negative_activations = batch_negative_activations / batch_negative_activations.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Compute mean across batch dimension\n",
    "    negative_mean_activations[layer] = batch_negative_activations.mean(dim=1)\n",
    "    negative_activations_all[layer] = batch_negative_activations\n",
    "\n",
    "print(negative_mean_activations.shape) # (n_layers, n_activations, d_model)\n",
    "print(negative_activations_all.shape) # (n_layers, n_activations, batch_size, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_mean_activation_normed = positive_mean_activations / positive_mean_activations.norm(dim=-1, keepdim=True)\n",
    "negative_mean_activation_normed = negative_mean_activations / negative_mean_activations.norm(dim=-1, keepdim=True)\n",
    "\n",
    "print(positive_mean_activation_normed.shape) # (n_layers, n_activations, d_model)\n",
    "print(negative_mean_activation_normed.shape) # (n_layers, n_activations, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_refusal_vectors = positive_mean_activation_normed.to(\"cpu\") - negative_mean_activation_normed.to(\"cpu\")\n",
    "candidate_refusal_vectors_normed = candidate_refusal_vectors / candidate_refusal_vectors.norm(dim=-1, keepdim=True)\n",
    "\n",
    "print(candidate_refusal_vectors_normed.shape) # (n_layers, n_activations, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8f36b",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393f6b9",
   "metadata": {},
   "source": [
    "### Scalar projections of activations onto the local refusal direction at each extraction point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6acb9ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m colour_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mplotly\u001b[49m\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mqualitative\u001b[38;5;241m.\u001b[39mPlotly[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m: plotly\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mqualitative\u001b[38;5;241m.\u001b[39mPlotly[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m: plotly\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mqualitative\u001b[38;5;241m.\u001b[39mPastel1[\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m colour_map_light \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m: plotly\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mqualitative\u001b[38;5;241m.\u001b[39mPastel1[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m: plotly\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mqualitative\u001b[38;5;241m.\u001b[39mPastel1[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m: plotly\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mqualitative\u001b[38;5;241m.\u001b[39mPastel1[\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m colour_map_opaque \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba(251, 180, 174, 0.3)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba(179, 205, 227, 0.3)\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \n\u001b[1;32m     15\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plotly' is not defined"
     ]
    }
   ],
   "source": [
    "colour_map = {\n",
    "    \"positive\": plotly.colors.qualitative.Plotly[0],\n",
    "    \"negative\": plotly.colors.qualitative.Plotly[1],\n",
    "    \"neutral\": plotly.colors.qualitative.Pastel1[3],\n",
    "\n",
    "}\n",
    "colour_map_light = {\n",
    "    \"positive\": plotly.colors.qualitative.Pastel1[1],\n",
    "    \"negative\": plotly.colors.qualitative.Pastel1[0],\n",
    "    \"neutral\": plotly.colors.qualitative.Pastel1[3],\n",
    "}\n",
    "colour_map_opaque = {\n",
    "    \"positive\": \"rgba(251, 180, 174, 0.3)\",\n",
    "    \"negative\": \"rgba(179, 205, 227, 0.3)\",   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b51ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "category2acts_normed = {\n",
    "    \"positive\": positive_activations_all.cpu(),\n",
    "    \"negative\": negative_activations_all.cpu(),\n",
    "} # (n_layers, n_activations, batch_size, num_last_tokens, d_model)\n",
    "\n",
    "\n",
    "x_values = [str(i) for i in range(2 * n_layers)]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for category in [\"positive\", \"negative\"]:\n",
    "    acts_normed = category2acts_normed[category] # (n_layers, n_activations, batch_size, d_model)\n",
    "    projections = einops.einsum(\n",
    "        candidate_refusal_vectors_normed,\n",
    "        acts_normed,\n",
    "        \"layer act dim, layer act batch dim -> layer act batch\",\n",
    "    )\n",
    "    projections = torch.tensor(projections)\n",
    "\n",
    "    mean_projection = projections.mean(dim=-1) # layer act batch -> layer act\n",
    "\n",
    "    y_values = mean_projection.flatten() # layer act -> layer * act\n",
    "\n",
    "\n",
    "    # mean\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values,\n",
    "            name=category,\n",
    "            mode=\"lines+markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map[category], size=3),\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values,\n",
    "            name=category,\n",
    "            mode=\"lines+markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map_light[category], size=3),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # variance\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=projections.reshape(-1, projections.shape[-1]),\n",
    "            name=category,\n",
    "            mode=\"lines+markers\",\n",
    "            yaxis=\"y\",\n",
    "            fillcolor=colour_map_opaque[category],\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # dot markers\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values[1::],\n",
    "            y=y_values[1::],\n",
    "            name=f\"{category}\",\n",
    "            mode=\"markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map[category], size=3),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    grid=dict(rows=1, columns=1),\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        title=dict(text=\"Extraction Point\", font=dict(size=20)),\n",
    "        dtick=4,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        tickfont=dict(size=18),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Scalar Projection\", font=dict(size=20)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        zeroline=False,\n",
    "        tickfont=dict(size=18),\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=250,\n",
    "    width=600,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    legend=dict(x=0.05, y=0.95, font=dict(size=18)),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"prj_onto_local_candidate_refusal_vectors.pdf\", scale=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4104d40b",
   "metadata": {},
   "source": [
    "### Mean cosine of refusal directions at each layer with at other layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "refusal_dirs = candidate_refusal_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9669fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = sum([[f\"{i}\", f\"{i}-post\"] for i in range(n_layers)], [])\n",
    "layer_names = [str(i) for i in range(2 * n_layers)]\n",
    "\n",
    "\n",
    "refusal_dirs_flatten = refusal_dirs.reshape((-1, refusal_dirs.shape[-1]))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=layer_names,\n",
    "        y=refusal_dirs_flatten.norm(dim=-1),\n",
    "        mode=\"lines+markers\",\n",
    "        yaxis=\"y\",\n",
    "        marker_color=colour_map_light[\"neutral\"],\n",
    "        marker_size=8,\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=layer_names[::],\n",
    "        y=refusal_dirs_flatten.norm(dim=-1)[::],\n",
    "        mode=\"markers\",\n",
    "        yaxis=\"y\",\n",
    "        marker_color=colour_map[\"neutral\"],\n",
    "        marker_size=8,\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(layer_names[np.argmax(refusal_dirs_flatten.norm(dim=-1)[:-1])])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=(\n",
    "    #     \"Statistics of refusal direction candidates at each layer\"\n",
    "    #     f\" layer for {MODEL_PATH}\"\n",
    "    # ),\n",
    "    plot_bgcolor=\"white\",\n",
    "    grid=dict(rows=1, columns=1),\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        title=dict(text=\"Extraction Point\", font=dict(size=28)),\n",
    "        dtick=4,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        tickfont=dict(size=24),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Norm of<br>Refusal Direction\", font=dict(size=28)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        zeroline=False,\n",
    "        tickfont=dict(size=24),\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=300,\n",
    "    width=1000,\n",
    "    # width=20 + 12 * len(x_values),\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# fig.write_image(VISUALIZATION_DIR / \"norm_refusal.pdf\", scale=5)\n",
    "\n",
    "\n",
    "flatten_dirs = refusal_dirs.reshape(-1, refusal_dirs.shape[-1])\n",
    "pairwise_cosine = flatten_dirs @ flatten_dirs.T\n",
    "# pairwise_cosine = np.arccos(pairwise_cosine)\n",
    "mean_cosine = np.nanmean(pairwise_cosine, axis=-1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=layer_names,\n",
    "        y=mean_cosine,\n",
    "        mode=\"lines+markers\",\n",
    "        yaxis=\"y\",\n",
    "        marker_color=colour_map_light[\"neutral\"],\n",
    "        showlegend=False,\n",
    "        marker_size=8,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=layer_names[::],\n",
    "        y=mean_cosine[::],\n",
    "        mode=\"markers\",\n",
    "        yaxis=\"y\",\n",
    "        marker_color=colour_map[\"neutral\"],\n",
    "        showlegend=False,\n",
    "        marker_size=8,\n",
    "    )\n",
    ")\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=layer_names,\n",
    "#         y=raw_dirs.norm(dim=-1) + mean_cosine / mean_cosine.max(),\n",
    "#         mode=\"lines+markers\",\n",
    "#         yaxis=\"y3\",\n",
    "#         marker_color=colour_map_light[\"neutral\"],\n",
    "#         showlegend=False\n",
    "#     )\n",
    "# )\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=(\n",
    "    #     \"Statistics of refusal direction candidates at each extraction point\"\n",
    "    #     f\" for {MODEL_PATH}\"\n",
    "    # ),\n",
    "    plot_bgcolor=\"white\",\n",
    "    grid=dict(rows=1, columns=1),\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        title=dict(text=\"Extraction Point\", font=dict(size=28)),\n",
    "        dtick=4,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        tickfont=dict(size=24),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=f\"Mean<br>Cosine Score\", font=dict(size=28)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        zeroline=False,\n",
    "        tickfont=dict(size=24),\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=300,\n",
    "    width=1000,\n",
    "    # width=20 + 12 * len(x_values),\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "layer_names[np.nanargmax(mean_cosine)]\n",
    "\n",
    "\n",
    "# fig.write_image(VISUALIZATION_DIR / \"mean_cosine.pdf\", scale=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a04e745",
   "metadata": {},
   "source": [
    "### Projection of activations by layers onto the final steering vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax = np.nanargmax(mean_cosine)\n",
    "max_mean_cosine_layer = argmax // 2\n",
    "max_mean_cosine_act_idx = argmax % 2\n",
    "\n",
    "chosen_layer = max_mean_cosine_layer\n",
    "chosen_act_idx = max_mean_cosine_act_idx\n",
    "chosen_token = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_plot(**kwargs):\n",
    "    x = kwargs.pop(\"x\")\n",
    "    y = kwargs.pop(\"y\")\n",
    "    y_mean = y.mean(dim=-1)\n",
    "    y_std = y.std(dim=-1)\n",
    "    y_upper = y_mean + y_std\n",
    "    y_lower = y_mean - y_std\n",
    "    y_upper = y_upper.tolist()\n",
    "    y_lower = y_lower.tolist()\n",
    "    # colour = kwargs.pop(\"color\")\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x=x + x[::-1],\n",
    "        y=y_upper + y_lower[::-1],\n",
    "        mode=\"lines\",\n",
    "        fill=\"toself\",\n",
    "        line=dict(color=kwargs[\"fillcolor\"], width=0),\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a61d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "category2acts_normed = {\n",
    "    \"positive\": positive_activations_all.cpu(),\n",
    "    \"negative\": negative_activations_all.cpu(),\n",
    "} # (n_layers, n_activations, batch_size, num_last_tokens, d_model)\n",
    "\n",
    "\n",
    "\n",
    "for category in [\"thinking\", \"no_thinking\"]:\n",
    "    acts_normed = category2acts_normed[category]\n",
    "\n",
    "    # layers x resid_modules x batch_size x dim\n",
    "    activations = acts_normed[..., chosen_token, :].clone()\n",
    "\n",
    "    # dim\n",
    "    direction = refusal_dirs[chosen_layer, chosen_act_idx].clone() #(d_model)\n",
    "\n",
    "    # layers x resid_modules x batch_size\n",
    "    scalar_projections = einops.einsum(\n",
    "        activations,\n",
    "        direction,\n",
    "        \"... batch_size dim, ... dim -> ... batch_size\",\n",
    "    )\n",
    "    scalar_projections = np.nan_to_num(scalar_projections)\n",
    "    print(category)\n",
    "    print(scalar_projections.mean())\n",
    "    degrees = np.rad2deg(np.arccos(scalar_projections))\n",
    "\n",
    "    y_values = scalar_projections\n",
    "\n",
    "    batch_size = scalar_projections.shape[-1]\n",
    "\n",
    "    # x_values_flatten = sum(\n",
    "    #     [\n",
    "    #         [f\"{l}-mid\"] * batch_size + [f\"{l}-post\"] * batch_size\n",
    "    #         for l in range(num_layers)\n",
    "    #     ],\n",
    "    #     [],\n",
    "    # )\n",
    "    x_values = sum([[f\"{l}\", f\"{l}-post\"] for l in range(n_layers)], [])\n",
    "    x_values = [str(i) for i in range(2 * n_layers)]\n",
    "\n",
    "    # variance\n",
    "    fig.add_trace(\n",
    "        variance_plot(\n",
    "            x=x_values,\n",
    "            y=torch.tensor(y_values).reshape(-1, degrees.shape[-1]),\n",
    "            yaxis=\"y\",\n",
    "            fillcolor=colour_map_opaque[category],\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # mean\n",
    "    ## for legend\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values.mean(axis=-1).flatten(),\n",
    "            mode=\"lines+markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map[category], size=3),\n",
    "            showlegend=True,\n",
    "            name=category,\n",
    "        )\n",
    "    )\n",
    "    ## for lines\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values.mean(axis=-1).flatten(),\n",
    "            mode=\"lines\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map_light[category], size=3),\n",
    "            showlegend=False,\n",
    "            name=category,\n",
    "        )\n",
    "    )\n",
    "    ## for markers\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values.mean(axis=-1).flatten(),\n",
    "            mode=\"markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map[category], size=3),\n",
    "            showlegend=False,\n",
    "            name=category,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    activations -= 2 * einops.einsum(\n",
    "        np.maximum(scalar_projections, 0),\n",
    "        direction,\n",
    "        \"layer resid_module batch_size, dim -> layer resid_module batch_size dim\",\n",
    "    )\n",
    "    scalar_projections = einops.einsum(\n",
    "        activations,\n",
    "        direction,\n",
    "        \"... batch_size dim, ... dim -> ... batch_size\",\n",
    "    )\n",
    "    print(category)\n",
    "    print(scalar_projections.mean())\n",
    "    degrees = np.rad2deg(np.arccos(scalar_projections))\n",
    "\n",
    "    y_values = scalar_projections\n",
    "\n",
    "\n",
    "module_names = [\"mid\", \"post\"]\n",
    "fig.update_layout(\n",
    "    grid=dict(rows=1, columns=1),\n",
    "    # yaxis=dict(tickformat=\".2E\"),\n",
    "    plot_bgcolor=\"white\",\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        dtick=4,\n",
    "        title=dict(text=\"Extraction Point\", font=dict(size=20)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        tickfont=dict(size=18),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Scalar Projections\", font=dict(size=20)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        zeroline=False,\n",
    "        tickfont=dict(size=18),\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=250,\n",
    "    width=600,\n",
    "    # title=(\n",
    "    #     \"Scalar projections of activations at each layer onto the chosen refusal direction\"\n",
    "    #     f\" ({chosen_layer}-{module_names[chosen_act_idx]})\"\n",
    "    # ),\n",
    "    # yaxis=dict(matches=None),\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    "    legend=dict(x=0.05, y=0.95, font=dict(size=18)),\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
