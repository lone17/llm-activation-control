{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "from typing import Literal\n",
    "from transformers import AutoTokenizer\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"Qwen/Qwen3-4B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0389c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These constants must match with the ones in get_activations.py\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "UPPERBOUND_MAX_NEW_TOKENS = 7000\n",
    "\n",
    "# Just hardcode to avoid loading the model\n",
    "start_thinking_token_id = 151667\n",
    "end_thinking_token_id = 151668 # Qwen3's end of thinking token id\n",
    "n_layers = 36\n",
    "# n_layers = model.config.num_hidden_layers\n",
    "n_activations = 2\n",
    "d_model = 2560"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf7a1f",
   "metadata": {},
   "source": [
    "## Load pre-computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed data\n",
    "positive_activations_all = torch.load(\"outputs/postive_activations_all.pt\")\n",
    "positive_activations_mean = torch.load(\"outputs/postive_activations_mean.pt\")\n",
    "positive_activations_mean_normed = torch.load(\"outputs/postive_activations_mean_normed.pt\")\n",
    "\n",
    "negative_activations_all = torch.load(\"outputs/negative_activations_all.pt\")\n",
    "negative_activations_mean = torch.load(\"outputs/negative_activations_mean.pt\")\n",
    "negative_activations_mean_normed = torch.load(\"outputs/negative_activations_mean_normed.pt\")\n",
    "\n",
    "candidate_refusal_vectors = torch.load(\"outputs/candidate_refusal_vectors.pt\")\n",
    "candidate_refusal_vectors_normed = torch.load(\"outputs/candidate_refusal_vectors_normed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "refusal_dirs = candidate_refusal_vectors\n",
    "print(refusal_dirs.shape) # (n_layers, n_activations, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71186760",
   "metadata": {},
   "source": [
    "## Select the best direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ce9e8",
   "metadata": {},
   "source": [
    "### Method 1: Max of mean cosine similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a5f77",
   "metadata": {},
   "source": [
    "#### Visualizations: Mean cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d60063",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_map = {\n",
    "    \"positive\": plotly.colors.qualitative.Plotly[0],\n",
    "    \"negative\": plotly.colors.qualitative.Plotly[1],\n",
    "    \"neutral\": plotly.colors.qualitative.Pastel1[3],\n",
    "\n",
    "}\n",
    "colour_map_light = {\n",
    "    \"positive\": plotly.colors.qualitative.Pastel1[1],\n",
    "    \"negative\": plotly.colors.qualitative.Pastel1[0],\n",
    "    \"neutral\": plotly.colors.qualitative.Pastel1[3],\n",
    "}\n",
    "colour_map_opaque = {\n",
    "    \"positive\": \"rgba(251, 180, 174, 0.3)\",\n",
    "    \"negative\": \"rgba(179, 205, 227, 0.3)\",   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = sum([[f\"{i}\", f\"{i}-post\"] for i in range(n_layers)], [])\n",
    "layer_names = [str(i) for i in range(2 * n_layers)]\n",
    "\n",
    "\n",
    "refusal_dirs_flatten = refusal_dirs.reshape((-1, refusal_dirs.shape[-1]))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=layer_names,\n",
    "        y=refusal_dirs_flatten.norm(dim=-1),\n",
    "        mode=\"lines+markers\",\n",
    "        yaxis=\"y\",\n",
    "        marker_color=colour_map_light[\"neutral\"],\n",
    "        marker_size=8,\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=layer_names[::],\n",
    "        y=refusal_dirs_flatten.norm(dim=-1)[::],\n",
    "        mode=\"markers\",\n",
    "        yaxis=\"y\",\n",
    "        marker_color=colour_map[\"neutral\"],\n",
    "        marker_size=8,\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(layer_names[np.argmax(refusal_dirs_flatten.norm(dim=-1)[:-1])])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=(\n",
    "    #     \"Statistics of refusal direction candidates at each layer\"\n",
    "    #     f\" layer for {MODEL_PATH}\"\n",
    "    # ),\n",
    "    plot_bgcolor=\"white\",\n",
    "    grid=dict(rows=1, columns=1),\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        title=dict(text=\"Extraction Point\", font=dict(size=28)),\n",
    "        dtick=4,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        tickfont=dict(size=24),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Norm of<br>Refusal Direction\", font=dict(size=28)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        zeroline=False,\n",
    "        tickfont=dict(size=24),\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=300,\n",
    "    width=1000,\n",
    "    # width=20 + 12 * len(x_values),\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# fig.write_image(VISUALIZATION_DIR / \"norm_refusal.pdf\", scale=5)\n",
    "\n",
    "\n",
    "flatten_dirs = refusal_dirs.reshape(-1, refusal_dirs.shape[-1])\n",
    "pairwise_cosine = flatten_dirs @ flatten_dirs.T\n",
    "# pairwise_cosine = np.arccos(pairwise_cosine)\n",
    "mean_cosine = np.nanmean(pairwise_cosine, axis=-1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=layer_names,\n",
    "        y=mean_cosine,\n",
    "        mode=\"lines+markers\",\n",
    "        yaxis=\"y\",\n",
    "        marker_color=colour_map_light[\"neutral\"],\n",
    "        showlegend=False,\n",
    "        marker_size=8,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=layer_names[::],\n",
    "        y=mean_cosine[::],\n",
    "        mode=\"markers\",\n",
    "        yaxis=\"y\",\n",
    "        marker_color=colour_map[\"neutral\"],\n",
    "        showlegend=False,\n",
    "        marker_size=8,\n",
    "    )\n",
    ")\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=layer_names,\n",
    "#         y=raw_dirs.norm(dim=-1) + mean_cosine / mean_cosine.max(),\n",
    "#         mode=\"lines+markers\",\n",
    "#         yaxis=\"y3\",\n",
    "#         marker_color=colour_map_light[\"neutral\"],\n",
    "#         showlegend=False\n",
    "#     )\n",
    "# )\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=(\n",
    "    #     \"Statistics of refusal direction candidates at each extraction point\"\n",
    "    #     f\" for {MODEL_PATH}\"\n",
    "    # ),\n",
    "    plot_bgcolor=\"white\",\n",
    "    grid=dict(rows=1, columns=1),\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        title=dict(text=\"Extraction Point\", font=dict(size=28)),\n",
    "        dtick=4,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        tickfont=dict(size=24),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=f\"Mean<br>Cosine Score\", font=dict(size=28)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        zeroline=False,\n",
    "        tickfont=dict(size=24),\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=300,\n",
    "    width=1000,\n",
    "    # width=20 + 12 * len(x_values),\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "layer_names[np.nanargmax(mean_cosine)]\n",
    "\n",
    "\n",
    "# fig.write_image(VISUALIZATION_DIR / \"mean_cosine.pdf\", scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best direction\n",
    "argmax = np.nanargmax(mean_cosine)\n",
    "max_mean_cosine_layer = argmax // 2\n",
    "max_mean_cosine_act_idx = argmax % 2\n",
    "\n",
    "chosen_layer = max_mean_cosine_layer\n",
    "chosen_act_idx = max_mean_cosine_act_idx\n",
    "chosen_token = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_direction = refusal_dirs[chosen_layer, chosen_act_idx] # (d_model)\n",
    "\n",
    "# save tensor\n",
    "torch.save(chosen_direction.to(\"cpu\"), \"outputs/chosen_direction.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329446c7",
   "metadata": {},
   "source": [
    "#### Visualization: Projection of activation vectors onto the chosen steering vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "refusal_dirs.shape # (n_layers, n_activations, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fbeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_plot(**kwargs):\n",
    "    x = kwargs.pop(\"x\")\n",
    "    y = kwargs.pop(\"y\")\n",
    "    y_mean = y.mean(dim=-1)\n",
    "    y_std = y.std(dim=-1)\n",
    "    y_upper = y_mean + y_std\n",
    "    y_lower = y_mean - y_std\n",
    "    y_upper = y_upper.tolist()\n",
    "    y_lower = y_lower.tolist()\n",
    "    # colour = kwargs.pop(\"color\")\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x=x + x[::-1],\n",
    "        y=y_upper + y_lower[::-1],\n",
    "        mode=\"lines\",\n",
    "        fill=\"toself\",\n",
    "        line=dict(color=kwargs[\"fillcolor\"], width=0),\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "category2acts_normed = {\n",
    "    \"positive\": positive_activations_all.cpu(),\n",
    "    \"negative\": negative_activations_all.cpu(),\n",
    "} # (n_layers, n_activations, batch_size, num_last_tokens, d_model)\n",
    "\n",
    "\n",
    "\n",
    "for category in [\"positive\", \"negative\"]:\n",
    "    acts_normed = category2acts_normed[category]\n",
    "\n",
    "    # layers x resid_modules x batch_size x dim\n",
    "    activations = acts_normed.clone()\n",
    "\n",
    "    # dim\n",
    "    direction = chosen_direction.clone() # (d_model)\n",
    "\n",
    "    # layers x resid_modules x batch_size\n",
    "    scalar_projections = einops.einsum(\n",
    "        activations,\n",
    "        direction,\n",
    "        \"... batch_size dim, ... dim -> ... batch_size\",\n",
    "    )\n",
    "    scalar_projections = np.nan_to_num(scalar_projections)\n",
    "    print(category)\n",
    "    print(scalar_projections.mean())\n",
    "    degrees = np.rad2deg(np.arccos(scalar_projections))\n",
    "\n",
    "    y_values = scalar_projections\n",
    "\n",
    "    batch_size = scalar_projections.shape[-1]\n",
    "\n",
    "    # x_values_flatten = sum(\n",
    "    #     [\n",
    "    #         [f\"{l}-mid\"] * batch_size + [f\"{l}-post\"] * batch_size\n",
    "    #         for l in range(num_layers)\n",
    "    #     ],\n",
    "    #     [],\n",
    "    # )\n",
    "    x_values = sum([[f\"{l}\", f\"{l}-post\"] for l in range(n_layers)], [])\n",
    "    x_values = [str(i) for i in range(2 * n_layers)]\n",
    "\n",
    "    # variance\n",
    "    fig.add_trace(\n",
    "        variance_plot(\n",
    "            x=x_values,\n",
    "            y=torch.tensor(y_values).reshape(-1, degrees.shape[-1]),\n",
    "            yaxis=\"y\",\n",
    "            fillcolor=colour_map_opaque[category],\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # mean\n",
    "    ## for legend\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values.mean(axis=-1).flatten(),\n",
    "            mode=\"lines+markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map[category], size=3),\n",
    "            showlegend=True,\n",
    "            name=category,\n",
    "        )\n",
    "    )\n",
    "    ## for lines\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values.mean(axis=-1).flatten(),\n",
    "            mode=\"lines\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map_light[category], size=3),\n",
    "            showlegend=False,\n",
    "            name=category,\n",
    "        )\n",
    "    )\n",
    "    ## for markers\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values.mean(axis=-1).flatten(),\n",
    "            mode=\"markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map[category], size=3),\n",
    "            showlegend=False,\n",
    "            name=category,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    activations -= 2 * einops.einsum(\n",
    "        np.maximum(scalar_projections, 0),\n",
    "        direction,\n",
    "        \"layer resid_module batch_size, dim -> layer resid_module batch_size dim\",\n",
    "    )\n",
    "    scalar_projections = einops.einsum(\n",
    "        activations,\n",
    "        direction,\n",
    "        \"... batch_size dim, ... dim -> ... batch_size\",\n",
    "    )\n",
    "    print(category)\n",
    "    print(scalar_projections.mean())\n",
    "    degrees = np.rad2deg(np.arccos(scalar_projections))\n",
    "\n",
    "    y_values = scalar_projections\n",
    "\n",
    "\n",
    "module_names = [\"mid\", \"post\"]\n",
    "fig.update_layout(\n",
    "    grid=dict(rows=1, columns=1),\n",
    "    # yaxis=dict(tickformat=\".2E\"),\n",
    "    plot_bgcolor=\"white\",\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        dtick=4,\n",
    "        title=dict(text=\"Extraction Point\", font=dict(size=20)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        tickfont=dict(size=18),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Scalar Projections\", font=dict(size=20)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        zeroline=False,\n",
    "        tickfont=dict(size=18),\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=250,\n",
    "    width=600,\n",
    "    # title=(\n",
    "    #     \"Scalar projections of activations at each layer onto the chosen refusal direction\"\n",
    "    #     f\" ({chosen_layer}-{module_names[chosen_act_idx]})\"\n",
    "    # ),\n",
    "    # yaxis=dict(matches=None),\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    "    legend=dict(x=0.05, y=0.95, font=dict(size=18)),\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
