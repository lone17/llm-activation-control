{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from typing import Literal\n",
    "from transformers import AutoTokenizer\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e966be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"Qwen/Qwen3-4B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05171be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These constants must match with the ones in get_activations.py\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "UPPERBOUND_MAX_NEW_TOKENS = 7000\n",
    "\n",
    "# Just hardcode to avoid loading the model\n",
    "start_thinking_token_id = 151667\n",
    "end_thinking_token_id = 151668 # Qwen3's end of thinking token id\n",
    "n_layers = 36\n",
    "# n_layers = model.config.num_hidden_layers\n",
    "n_activations = 2\n",
    "d_model = 2560"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69882e3d",
   "metadata": {},
   "source": [
    "## Load pre-computed activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0056a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD THE PATH TO ACTIVATIONS HERE\n",
    "activation_path = Path(\"\")\n",
    "assert activation_path.exists()\n",
    "\n",
    "# Load the activations\n",
    "sequences_activations = torch.load(activation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert len(sequences_activations) == TRAIN_BATCH_SIZE\n",
    "print(sequences_activations[0][\"generated_token_ids\"].shape) # (1, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e38c74",
   "metadata": {},
   "source": [
    "## Compute candidate directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab88f90",
   "metadata": {},
   "source": [
    "### Scenario 1: Positive: `<think>` - Negative: `</think>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269e9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the start thinking and end thinking positions in each sequence\n",
    "start_thinking_positions = []\n",
    "end_thinking_positions = []\n",
    "for seq in sequences_activations:\n",
    "    start_thinking_positions.append((seq[\"generated_token_ids\"][0] == start_thinking_token_id).nonzero(as_tuple=True)[0].item())\n",
    "    try:\n",
    "        end_thinking_positions.append((seq[\"generated_token_ids\"][0] == end_thinking_token_id).nonzero(as_tuple=True)[0].item())\n",
    "    except:\n",
    "        # Some sequences do not have the end thinking token\n",
    "        end_thinking_positions.append(None)\n",
    "\n",
    "print(start_thinking_positions)\n",
    "print(end_thinking_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6548fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: validate if the end positions are the correct end of thinking tokens\n",
    "first_end_thinking_token_ids = sequences_activations[0][\"generated_token_ids\"][0][end_thinking_positions[0]]\n",
    "print(first_end_thinking_token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0565501",
   "metadata": {},
   "source": [
    "#### Get positive and negative activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e39931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get positive\n",
    "batch_positive_caches = [] \n",
    "for i, seq in enumerate(sequences_activations):\n",
    "    token_activations = seq[\"token_activations\"]\n",
    "    positive = {}\n",
    "    for module_path, activations in token_activations.items():\n",
    "        positive[module_path] = activations[0, start_thinking_positions[i], :] # (d_model)\n",
    "    batch_positive_caches.append(positive)\n",
    "\n",
    "print(batch_positive_caches[0][\"model.layers.0.input_layernorm\"].shape) # (d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ca90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get negative\n",
    "batch_negative_caches = []\n",
    "for i,seq in enumerate(sequences_activations):\n",
    "    token_activations = seq[\"token_activations\"]\n",
    "    negative = {}\n",
    "    for module_path, activations in token_activations.items():\n",
    "        negative[module_path] = activations[0, end_thinking_positions[i], :] # (d_model)\n",
    "    batch_negative_caches.append(negative)\n",
    "\n",
    "print(batch_negative_caches[0][\"model.layers.0.input_layernorm\"].shape) # (d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22432b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module_path(\n",
    "    layer: int,\n",
    "    module_name: Literal[\"input_layernorm\", \"post_attention_layernorm\"] = [\"input_layernorm\", \"post_attention_layernorm\"]\n",
    ") -> str:\n",
    "    return f\"model.layers.{layer}.{module_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_activations_mean = torch.zeros(\n",
    "    n_layers, n_activations, d_model, device=\"cpu\", dtype=torch.float16\n",
    ") # (n_layers, n_activations, d_model)\n",
    "\n",
    "positive_activations_all = torch.zeros(\n",
    "    n_layers, n_activations, TRAIN_BATCH_SIZE, d_model, device=\"cpu\", dtype=torch.float16\n",
    ") # (n_layers, n_activations, batch_size, d_model)\n",
    "\n",
    "for layer in range(n_layers):\n",
    "    batch_positive_activations = []\n",
    "    for module_name in [\"input_layernorm\", \"post_attention_layernorm\"]:\n",
    "        # Get mean activations across tokens dimension\n",
    "        batch_positive_activations_per_module = []\n",
    "        for i, sample in enumerate(batch_positive_caches):\n",
    "            try:\n",
    "                batch_positive_activations_per_module.append(\n",
    "                    sample[get_module_path(layer, module_name)] # (d_model)\n",
    "                )\n",
    "            except:\n",
    "                print(i)\n",
    "        batch_positive_activations_per_module = torch.stack(batch_positive_activations_per_module)\n",
    "        batch_positive_activations.append(batch_positive_activations_per_module)\n",
    "    batch_positive_activations = torch.stack(batch_positive_activations) # (n_activations, batch_size, d_model)\n",
    "\n",
    "    # Normalize then get mean because the activation will be normalized by the RMSNorm layer\n",
    "    batch_positive_activations = batch_positive_activations / batch_positive_activations.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Compute mean along the batch dimension\n",
    "    postive_activations_mean[layer] = batch_positive_activations.mean(dim=1)\n",
    "    positive_activations_all[layer] = batch_positive_activations\n",
    "\n",
    "print(postive_activations_mean.shape) # (n_layers, n_activations, num_last_tokens, d_model)\n",
    "print(positive_activations_all.shape) # (n_layers, n_activations, batch_size, num_last_tokens, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_activations_mean = torch.zeros(\n",
    "    n_layers, n_activations, d_model, device=\"cpu\", dtype=torch.float16\n",
    ") # (n_layers, n_activations, d_model)\n",
    "\n",
    "negative_activations_all = torch.zeros(\n",
    "    n_layers, n_activations, TRAIN_BATCH_SIZE, d_model, device=\"cpu\", dtype=torch.float16\n",
    ") # (n_layers, n_activations, batch_size, d_model)\n",
    "\n",
    "for layer in range(n_layers):\n",
    "    batch_negative_activations = []\n",
    "    for module_name in [\"input_layernorm\", \"post_attention_layernorm\"]:\n",
    "        # Get mean activations across tokens dimension\n",
    "        batch_negative_activations_per_module = []\n",
    "        for i, sample in enumerate(batch_negative_caches):\n",
    "            try:\n",
    "                batch_negative_activations_per_module.append(\n",
    "                    sample[get_module_path(layer, module_name)] # (d_model)\n",
    "                )\n",
    "            except:\n",
    "                print(i)\n",
    "        batch_negative_activations_per_module = torch.stack(batch_negative_activations_per_module) # (batch_size, d_model)\n",
    "        batch_negative_activations.append(batch_negative_activations_per_module)\n",
    "    batch_negative_activations = torch.stack(batch_negative_activations) # (n_activations, batch_size, d_model)\n",
    "\n",
    "    # Normalize then get mean because the activation will be normalized by the RMSNorm layer\n",
    "    batch_negative_activations = batch_negative_activations / batch_negative_activations.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Compute mean across batch dimension\n",
    "    negative_activations_mean[layer] = batch_negative_activations.mean(dim=1)\n",
    "    negative_activations_all[layer] = batch_negative_activations\n",
    "\n",
    "print(negative_activations_mean.shape) # (n_layers, n_activations, d_model)\n",
    "print(negative_activations_all.shape) # (n_layers, n_activations, batch_size, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c07b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_activations_mean_normed = postive_activations_mean / postive_activations_mean.norm(dim=-1, keepdim=True)\n",
    "\n",
    "negative_activations_mean_normed = negative_activations_mean / negative_activations_mean.norm(dim=-1, keepdim=True)\n",
    "\n",
    "print(postive_activations_mean_normed.shape) # (n_layers, n_activations, d_model)\n",
    "print(negative_activations_mean_normed.shape) # (n_layers, n_activations, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to disk\n",
    "# torch.save(positive_activations_all, \"outputs/postive_activations_all.pt\")\n",
    "# torch.save(postive_activations_mean, \"outputs/postive_activations_mean.pt\")\n",
    "# torch.save(postive_activations_mean_normed, \"outputs/postive_activations_mean_normed.pt\")\n",
    "\n",
    "# torch.save(negative_activations_all, \"outputs/negative_activations_all.pt\")\n",
    "# torch.save(negative_activations_mean, \"outputs/negative_activations_mean.pt\")\n",
    "# torch.save(negative_activations_mean_normed, \"outputs/negative_activations_mean_normed.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f916e4d",
   "metadata": {},
   "source": [
    "## Compute candidate directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10fa945",
   "metadata": {},
   "source": [
    "#### Difference-in-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_refusal_vectors = postive_activations_mean_normed.to(\"cpu\") - negative_activations_mean_normed.to(\"cpu\")\n",
    "candidate_refusal_vectors_normed = candidate_refusal_vectors / candidate_refusal_vectors.norm(dim=-1, keepdim=True)\n",
    "\n",
    "print(candidate_refusal_vectors_normed.shape) # (n_layers, n_activations, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "torch.save(candidate_refusal_vectors, \"outputs/candidate_refusal_vectors.pt\")\n",
    "torch.save(candidate_refusal_vectors_normed, \"outputs/candidate_refusal_vectors_normed.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e56ec7",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558d5f5",
   "metadata": {},
   "source": [
    "### Scalar projections of activations onto the local refusal direction at each extraction point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec68460",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_map = {\n",
    "    \"positive\": plotly.colors.qualitative.Plotly[0],\n",
    "    \"negative\": plotly.colors.qualitative.Plotly[1],\n",
    "    \"neutral\": plotly.colors.qualitative.Pastel1[3],\n",
    "\n",
    "}\n",
    "colour_map_light = {\n",
    "    \"positive\": plotly.colors.qualitative.Pastel1[1],\n",
    "    \"negative\": plotly.colors.qualitative.Pastel1[0],\n",
    "    \"neutral\": plotly.colors.qualitative.Pastel1[3],\n",
    "}\n",
    "colour_map_opaque = {\n",
    "    \"positive\": \"rgba(251, 180, 174, 0.3)\",\n",
    "    \"negative\": \"rgba(179, 205, 227, 0.3)\",   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "category2acts_normed = {\n",
    "    \"positive\": positive_activations_all.cpu(),\n",
    "    \"negative\": negative_activations_all.cpu(),\n",
    "} # (n_layers, n_activations, batch_size, num_last_tokens, d_model)\n",
    "\n",
    "\n",
    "x_values = [str(i) for i in range(2 * n_layers)]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for category in [\"positive\", \"negative\"]:\n",
    "    acts_normed = category2acts_normed[category] # (n_layers, n_activations, batch_size, d_model)\n",
    "    projections = einops.einsum(\n",
    "        candidate_refusal_vectors_normed,\n",
    "        acts_normed,\n",
    "        \"layer act dim, layer act batch dim -> layer act batch\",\n",
    "    )\n",
    "    projections = torch.tensor(projections)\n",
    "\n",
    "    mean_projection = projections.mean(dim=-1) # layer act batch -> layer act\n",
    "\n",
    "    y_values = mean_projection.flatten() # layer act -> layer * act\n",
    "\n",
    "\n",
    "    # mean\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values,\n",
    "            name=category,\n",
    "            mode=\"lines+markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map[category], size=3),\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values,\n",
    "            name=category,\n",
    "            mode=\"lines+markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map_light[category], size=3),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # variance\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values,\n",
    "            y=projections.reshape(-1, projections.shape[-1]),\n",
    "            name=category,\n",
    "            mode=\"lines+markers\",\n",
    "            yaxis=\"y\",\n",
    "            fillcolor=colour_map_opaque[category],\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # dot markers\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_values[1::],\n",
    "            y=y_values[1::],\n",
    "            name=f\"{category}\",\n",
    "            mode=\"markers\",\n",
    "            yaxis=\"y\",\n",
    "            marker=dict(color=colour_map[category], size=3),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    grid=dict(rows=1, columns=1),\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        title=dict(text=\"Extraction Point\", font=dict(size=20)),\n",
    "        dtick=4,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        tickfont=dict(size=18),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Scalar Projection\", font=dict(size=20)),\n",
    "        gridcolor=\"lightgrey\",\n",
    "        zeroline=False,\n",
    "        tickfont=dict(size=18),\n",
    "    ),\n",
    "    hovermode=\"x unified\",\n",
    "    height=250,\n",
    "    width=600,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    legend=dict(x=0.05, y=0.95, font=dict(size=18)),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# fig.write_image(\"prj_onto_local_candidate_refusal_vectors.pdf\", scale=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
